---
layout: post
title:      "Capstone Project"
date:       2020-12-05 15:55:16 -0500
permalink:  capstone_project
---


2020 has been an unprecedented year in almost every way imaginable, and the 2020 election was no exception. As I write this, all eyes continue to be on Georgia as control of the Senate rests on the two runoff elections to be run in 2021. I have always been passionate about political issues; my middle school diary has a digression from the drama characterizing my pre-teen life reporting on the results of the 2008 Iowa caucus and noting my preferred candidate. Given that this project began in the immediate aftermath of the 2020 election, trying to predict the outcomes of Senate races felt like a worthy topic of examination. 
The most important aspect of this project was the data collection. While it can feel like the goal is to deploy as complex a model or visual as possible, oftentimes the best way to answer a question is to find the right information. I began this project with the goal of predicting the outcome of Senate races based on state-level variables. There was a large compilation of state policy and demographic variables made available by the Michigan State University and Senate data by year was easy to find on data.world. However there was not consistent data across years. Additionally, while I had initially set out to simply predict the outcome of Senate races, once I stumbled upon a large-scale survey of voters in the Harvard dataverse, I became more interested in looking at individual voters rather than race outcomes. However the state data I had collected thus far did not cover all of the years of the survey. Thus began the most significant portion of this project: filling in the gaps. I knew that there were some variables I could not measure, such as the work of activists to increase voter participation, so I used turnout and voting laws to approximate the impact these organizers have. For population level variables, I turned mostly to the Census Bureau, sorting through their tables from each year. However I also used data from the Kaiser Family Foundation, the Congressional Research Service, Iowa State University, and Harvard’s dataverse to fill in missing data. 
Some variables, such as which places were impacted by the Supreme Court case Shelby v Holder, were not available in the form of a data table and I simply had to do research to understand which states were affected and what impact the case had on these states’ elections. Other variables, such as each state’s policy on voter ID and other such laws in recent years, had to be manually inputted. Thanks to various news articles and the National Conference of State Legislatures, I was able to pinpoint when changes in the laws occurred and input the data accordingly. In addition I scrapped unemployment data that had not being compiled and put in a downloadable form from the U.S. Bureau of Labor Statistics. Even after this work, there were still some holes in the wait time data, so I simply filled in the previous election’s data. 
My process of choosing which variables to use was a combination of availability and research. For instance, it was important for me to add voter wait time data to my existing variables because longer wait times can be the result of voter suppression, which can change the outcome of a race. However there were variables I wanted to use that were present in the Correlates of State Policy project, such as the interest group density or campaign finance laws, but the information did not fall in my date range. It was important to me that I had the basic demographic and economic variables (like turnout, percentage non-white, minimum wage, percent of workforce in a union, etc.) because this gives a lot of information about the state itself. I also wanted to have as many election laws as possible, such as whether same-day voter registration is allowed, to get an accurate picture of how accessible voting is. As far as the person-level variables, I used most of the variables provided in the dataset. Obviously there was no way to supplement data on the individuals and this was the most comprehensive survey I could locate.
The bulk of the time once the date were collected was spent cleaning the data and combining it into one large dataset using pandasql. There were over 900 variables in the Correlates of State Policy Project alone so deciding what to keep, how to format data, and what variables to create also took significant time. I wanted to track changes by year so I calculated a percent change in the relevant columns from election to election. I also calculated the population density to further illuminate the way people live in each state.  
Once the data were combined and missing data filled in, I moved on to answering the central questions. In the end we tried to predict whether people registered with one of the major parties would vote for or against their party in a Senate race. The second question was whether we could predict what party people not registered with either party would vote for. Ultimately we ended up with two random forest models optimized via grid searches. While we tried other types of models, the random forests still achieved comparable or better results than the more complex models but are much less resource intensive and produce results more quickly. Disapproval of presidents and senators, population-related variables, and economic variables were most influential for both models.  
We concluded that Democrats should prioritize voters in states with a higher percentage of non-white individuals and greater numbers of voting-age and voting-eligible because they are more likely to defect while Republicans should focus on the opposite. We also found that focus on the economy is a strong position for Republicans. Democrats need to present a stronger case to swing voters when the economy is declining and unemployment is going up. Lastly we found that both parties must find ways to mitigate the impact of disapproval of the president when their party is in power.

